{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trade off between S, Tmin, and Tmax\n",
    "\n",
    "In this notebook we investigate the trade off between S, Tmin and Tmax when fitting the log heal model to the data.\n",
    "\n",
    "2022.04.29 Kurama Okubo\n",
    "\n",
    "- 2022.04.30 Update using real data of dv/v\n",
    "- 2023.10.6 update notation of label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import time\n",
    "import pickle\n",
    "import h5py\n",
    "import emcee # MCMC sampler\n",
    "import corner\n",
    "import copy\n",
    "from scattermatrix import *\n",
    "from MCMC_func import *\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# modules used for Low level callback function duting integration\n",
    "import os, ctypes\n",
    "from scipy import integrate, LowLevelCallable\n",
    "import matplotlib.dates as dates\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "plt.rcParams[\"font.family\"] = 'Arial'\n",
    "# plt.rcParams[\"font.sans-serif\"] = \"DejaVu Sans, Arial, Helvetica, Lucida Grande, Verdana, Geneva, Lucid, Avant Garde, sans-serif\"\n",
    "plt.rcParams[\"font.size\"] = 12\n",
    "plt.rcParams[\"xtick.direction\"] = \"in\"\n",
    "plt.rcParams[\"xtick.major.size\"] = 4.75\n",
    "plt.rcParams[\"xtick.major.width\"] = 0.75\n",
    "plt.rcParams[\"xtick.minor.size\"] = 3\n",
    "plt.rcParams[\"xtick.minor.width\"] = 0.4\n",
    "plt.rcParams[\"xtick.minor.visible\"] = True\n",
    "\n",
    "plt.rcParams[\"ytick.direction\"] = \"in\"\n",
    "plt.rcParams[\"ytick.major.size\"] = 4.75\n",
    "plt.rcParams[\"ytick.major.width\"] = 0.75\n",
    "plt.rcParams[\"ytick.minor.size\"] = 3\n",
    "plt.rcParams[\"ytick.minor.width\"] = 0.4\n",
    "plt.rcParams[\"ytick.minor.visible\"] = True\n",
    "\n",
    "plt.rcParams[\"savefig.transparent\"] = True\n",
    "\n",
    "plt.rcParams['axes.linewidth'] = 0.75\n",
    "\n",
    "os.environ['TZ'] = 'GMT' # change time zone to avoid confusion in unix_tvec conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_imgdir = \"../figure\"\n",
    "output_datadir = \"../data\"\n",
    "\n",
    "if not os.path.exists(output_imgdir):\n",
    "    os.makedirs(output_imgdir)\n",
    "    \n",
    "if not os.path.exists(output_datadir):\n",
    "    os.makedirs(output_datadir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process flow\n",
    "1. Read dv/v data from channel weighted dv/v.\n",
    "\n",
    "2. Remove the factors of precipitation, temperature and linear trend with maximum likelihood model parameters.\n",
    "\n",
    "3. Apply MCMC with the tmin.\n",
    "\n",
    "4. Compare the result to see the trade off."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Preprocess dv/v data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"../../../Post/ModelFit/processed_data/\"\n",
    "h5_stats_list = [root+\"02dvvanderr_formodelfit_chanweighted_dvvtraces_chanweighted_monitoring_stats_uwbackup_2010-2022_stretching.csv_0.9-1.2.h5\",\n",
    "                    root+\"02dvvanderr_formodelfit_chanweighted_dvvtraces_chanweighted_monitoring_stats_uwbackup_2010-2022_mwcs.csv_0.9-1.2.h5\"]\n",
    "\n",
    "starttime = datetime.datetime(2002, 1, 1)\n",
    "endtime = datetime.datetime(2022, 6, 1)\n",
    "\n",
    "refstarttime = datetime.datetime(2010, 1, 1)\n",
    "refendtime = datetime.datetime(2022, 6, 1)\n",
    "\n",
    "vlines = [datetime.datetime(2003, 12, 22), datetime.datetime(2004, 9, 28)] \n",
    "\n",
    "h5_id = 1 # use mwcs\n",
    "modelcase = \"wlin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "casename = os.path.basename(h5_stats_list[h5_id].split('.h5')[0])\n",
    "freqband = h5_stats_list[h5_id].split('.h5')[0].split('_')[-1]\n",
    "dvvmethod = casename.split('.csv')[0].split('_')[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select target station pair\n",
    "stationpair = \"BP.VCAB-BP.VCAB\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi = h5py.File(h5_stats_list[h5_id], \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniform_tvec_unix = np.array(fi[\"uniform_tvec\"])\n",
    "uniform_tvec = np.array([datetime.datetime.fromtimestamp(x) for x in uniform_tvec_unix])\n",
    "dvv_data = np.array(fi[\"dvv/{}/dvv\".format(stationpair)])\n",
    "err_data = np.array(fi[\"dvv/{}/err\".format(stationpair)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read model parameters\n",
    "finame = f\"../../../Post/ModelFit/modelparam_data/MCMC_modelparam_{stationpair}_{dvvmethod}_{freqband}Hz_{modelcase}.pickle\"\n",
    "with open(finame, \"rb\") as f:\n",
    "    modelparam = pickle.load(f)\n",
    "\n",
    "modelparam[\"ndim\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a0                -0.04268\n",
       "p1               -0.006957\n",
       "a_{precip}         0.03888\n",
       "p2               -0.001166\n",
       "t_{shiftdays}    54.524917\n",
       "S1                0.020048\n",
       "log10tmin1           4.903\n",
       "log10tmax1        7.879847\n",
       "S2                0.042516\n",
       "log10tmin2           6.993\n",
       "log10tmax2        8.171853\n",
       "b_{lin}           0.000009\n",
       "logf             -3.631456\n",
       "Name: BP.VCAB-BP.VCAB, dtype: object"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read best fit model paramters\n",
    "df_param = pd.read_csv(f\"../../../Post/ModelFit/data_stats/MCMC_modelparam_all_{dvvmethod}_{freqband}_wlin.csv\", index_col=0)\n",
    "df_pair = df_param.loc[stationpair]\n",
    "theta_series = df_pair[3:16]\n",
    "theta_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute dv/v components\n",
    "dvvmodel, dvvgwl, dvvtemp, dvvhealSS, dvvhealPF, lintrend = model_wlin(theta_series.values, all=True, **modelparam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot figure\n",
    "dvvmodel_IsOffsetRemoval = True # remove offset from the dv/v with the periof before San Simeon eq. of the observation\n",
    "tSS = datetime.datetime(2003, 12, 22) # time for San Simeon\n",
    "t_shiftdays = theta_series[4]\n",
    "\n",
    "fig, axs = plt.subplots(6, 1, figsize=(10,12),sharex=True)\n",
    "\n",
    "# plot GWL\n",
    "axs[0].plot(uniform_tvec, dvvgwl, \"k-\")\n",
    "axs[0].set_title(\"ΔGWL\")\n",
    "axs[0].set_ylabel(\"dv/v[%]\")\n",
    "\n",
    "ax02=axs[0].twinx()\n",
    "# make a plot with different y-axis using second axis object\n",
    "ax02.plot(uniform_tvec, modelparam[\"precip\"] , color=\"blue\")\n",
    "ax02.set_ylabel(\"Precipitation [mm/month]\",color=\"blue\")\n",
    "ax02.set_ylim([0, 250])\n",
    "\n",
    "\n",
    "# plot Temperature\n",
    "axs[1].plot(uniform_tvec, dvvtemp, \"k-\", label=\"{:2d} days shifted\".format(int(t_shiftdays)))\n",
    "axs[1].set_title(\"Temperature\")\n",
    "axs[1].set_ylabel(\"dv/v[%]\")\n",
    "\n",
    "ax12=axs[1].twinx()\n",
    "# make a plot with different y-axis using second axis object\n",
    "ax12.plot(uniform_tvec, modelparam[\"CAVG\"] , color=\"orange\")\n",
    "ax12.set_ylabel(\"ΔTemperature [°C]\",color=\"orange\")\n",
    "ax12.set_ylim([-20, 20])\n",
    "axs[1].legend(loc=4, bbox_to_anchor=(1.02, 1.0),)\n",
    "\n",
    "\n",
    "# plot SS and PF healing\n",
    "axs[2].plot(uniform_tvec, dvvhealSS, \"k-\", label=\"San Simeon EQ.\")\n",
    "axs[2].plot(uniform_tvec, dvvhealPF, \"r-\", label=\"Parkfield EQ.\")\n",
    "axs[2].set_title(\"Healing model\")\n",
    "axs[2].set_ylabel(\"dv/v[%]\")\n",
    "axs[2].legend(loc=4)\n",
    "\n",
    "# plot trend\n",
    "if modelparam[\"modelcase\"] == \"base\":\n",
    "    lintrend = np.zeros(len(uniform_tvec)) # plot zero trend for the case of base model\n",
    "    \n",
    "axs[3].plot(uniform_tvec, lintrend, ls=\"-\", c = \"k\", zorder=1)\n",
    "axs[3].set_title(\"Linear trend\")\n",
    "axs[3].set_ylabel(\"dv/v [%]\")\n",
    "# axs[3].legend(loc=4)\n",
    "\n",
    "# plot dv/v\n",
    "if dvvmodel_IsOffsetRemoval:\n",
    "    offset_ind = np.where(np.array(uniform_tvec) < tSS)\n",
    "    offset_data = np.nanmean(dvv_data[offset_ind])\n",
    "    dvv_data = dvv_data - offset_data\n",
    "    dvvmodel = dvvmodel - offset_data\n",
    "    axs[4].text(starttime, -0.27, \" offset removed\")\n",
    "    \n",
    "# axs[3].errorbar(uniform_tvec, dvv_data, yerr = err_data, capsize=3, ls=\"-\", c = \"k\", ecolor='black', zorder=1, label=\"data\")\n",
    "axs[4].plot(uniform_tvec, dvv_data, ls=\"-\", c = \"k\", zorder=1, label=\"data\")\n",
    "axs[4].plot(uniform_tvec, dvvmodel, \"r-\", zorder=2, label=\"model\")\n",
    "axs[4].set_title(\"Model fit with observation\")\n",
    "axs[4].set_ylabel(\"dv/v [%]\")\n",
    "axs[4].legend(loc=4)\n",
    "\n",
    "# plot residual\n",
    "axs[5].plot(uniform_tvec, dvv_data-dvvmodel, \"-\", c=\"gray\", zorder=2, label=\"residual\")\n",
    "axs[5].plot(uniform_tvec, moving_average(dvv_data-dvvmodel, 20), \"k-\", zorder=2, label=\"smoothed\")\n",
    "axs[5].set_title(\"Residual\")\n",
    "axs[5].set_ylabel(\"Δdv/v [%]\")\n",
    "axs[5].legend(loc=4)\n",
    "\n",
    "for i in range(len(axs)):\n",
    "    axs[i].grid(True)\n",
    "    axs[i].set_yticks([-0.2, 0.0, 0.2])\n",
    "\n",
    "plt.setp(axs, xlim=[starttime, endtime])\n",
    "plt.setp(axs, ylim=[-0.2,0.2])\n",
    "\n",
    "Nmodelparam = len(theta_series)\n",
    "AIC_wlin = compute_AIC(dvv_data*1e-2, dvvmodel*1e-2, Nmodelparam) # convert from % to nondim\n",
    "BIC_wlin = compute_BIC(dvv_data*1e-2, dvvmodel*1e-2, Nmodelparam) # convert from % to nondim\n",
    "\n",
    "plt.suptitle(\"{} {} {} AIC:{:4.2f} BIC:{:4.2f}\".format(dvvmethod, stationpair, freqband, AIC_wlin, BIC_wlin))\n",
    "\n",
    "fig.tight_layout()\n",
    "# vlines = [datetime.datetime(2002, 1, 1), datetime.datetime(2020, 9, 1)] \n",
    "# ax.axvline(vlines[0], ls=\"-\", c='b')\n",
    "# ax.axvline(vlines[1], ls=\"-\", c='b')\n",
    "\n",
    "foname = (output_imgdir+\"/tradeoff_logheal_modelfit_factors_{}_{}_{}_{}.png\".format(stationpair, dvvmethod, freqband, modelparam[\"modelcase\"]))\n",
    "plt.savefig(foname, dpi=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Remove the dv/v factors associated with precipitation, temperature, and linear trend and Log heal by the San Simeon earthquake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the\n",
    "dvv_removalcomp = theta_series[\"a0\"] + dvvgwl + dvvtemp + dvvhealSS + lintrend # components to be removed\n",
    "\n",
    "if dvvmodel_IsOffsetRemoval:\n",
    "#     offset_ind = np.where(np.array(uniform_tvec) < tSS)\n",
    "#     offset_data = np.nanmean(dvv_data[offset_ind])\n",
    "    dvv_removalcomp = dvv_removalcomp - offset_data\n",
    "    \n",
    "dvv_data_PF = dvv_data - dvv_removalcomp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(13,3))\n",
    "\n",
    "ax.plot(uniform_tvec, dvv_data, \"r--\", lw=0.8, label=\"raw data\")\n",
    "ax.plot(uniform_tvec, dvv_data_PF, \"k-\", lw=1, label=\"After removal of model components\")\n",
    "\n",
    "\n",
    "xfmt = dates.DateFormatter('%Y')\n",
    "\n",
    "ax.set_ylim(-0.22, 0.15)\n",
    "ax.set_yticks(np.linspace(-0.20, 0.15, 8))\n",
    "ax.set_ylabel(\"dv/v [%]\")\n",
    "ax.set_xlim(starttime, endtime)\n",
    "ax.grid(True, axis=\"both\", lw=0.5, c=[0.8, 0.8, 0.8], alpha=0.4, zorder=-20)\n",
    "\n",
    "# annotate reference period\n",
    "refy = -0.27\n",
    "ax.annotate('', xy=(refstarttime, refy), xytext=(refendtime, refy), arrowprops=dict(arrowstyle='<->'), annotation_clip=False)\n",
    "ax.text(datetime.datetime(2016,6,1), -0.28, \"reference stack period\", ha=\"center\", va='top')\n",
    "# axs[1].plot([refstarttime, refendtime], [-0.3, -0.3], clip_on=False,)\n",
    "\n",
    "ax.set_title(f\"channel weighted {stationpair} {dvvmethod}: {freqband}Hz\")\n",
    "ax.legend(loc=8)\n",
    "\n",
    "foname = (output_imgdir+\"/tradeoff_logheal_dvvafterremovalfactors_{}_{}_{}_{}.png\".format(stationpair, dvvmethod, freqband, modelparam[\"modelcase\"]))\n",
    "plt.savefig(foname, dpi=150, bbox_inches='tight')\n",
    "\n",
    "foname = (output_imgdir+\"/tradeoff_logheal_dvvafterremovalfactors_{}_{}_{}_{}.eps\".format(stationpair, dvvmethod, freqband, modelparam[\"modelcase\"]))\n",
    "plt.savefig(foname, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data for master plot\n",
    "masterplot_data = dict(stationpair=stationpair, dvvmethod=dvvmethod, freqband=freqband, modelcase=modelparam[\"modelcase\"],\n",
    "                                   uniform_tvec=uniform_tvec, unix_tvec=modelparam[\"unix_tvec\"], unix_SS=modelparam[\"unix_tSS\"], unix_tPF=modelparam[\"unix_tPF\"],\n",
    "                                   dvv_data=dvv_data, dvv_data_PF = dvv_data_PF,\n",
    "                                   )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the fitting period\n",
    "xlimit_focus = [datetime.datetime(2003, 1, 1), datetime.datetime(2010, 1, 1)]\n",
    "fitting_period_ind = np.where((uniform_tvec >= xlimit_focus[0]) & (uniform_tvec <= xlimit_focus[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(7,3))\n",
    "\n",
    "ax.plot(uniform_tvec[fitting_period_ind], dvv_data[fitting_period_ind], \"r--\", lw=0.8, label=\"raw data\")\n",
    "ax.plot(uniform_tvec[fitting_period_ind], dvv_data_PF[fitting_period_ind], \"ko-\", lw=1, markerfacecolor=\"w\", ms=4, label=\"After removal of model components\")\n",
    "\n",
    "\n",
    "ax.set_ylim(-0.22, 0.15)\n",
    "ax.set_yticks(np.linspace(-0.20, 0.15, 8))\n",
    "ax.set_ylabel(\"dv/v [%]\")\n",
    "# ax.set_xlim(xlimit_focus)\n",
    "ax.grid(True, axis=\"both\", lw=0.5, c=[0.8, 0.8, 0.8], alpha=0.4, zorder=-20)\n",
    "\n",
    "ax.axvline(vlines[1], color='k', linewidth=0.5, linestyle='--', zorder=2)\n",
    "ax.set_title(f\"channel weighted {stationpair} {dvvmethod}: {freqband}Hz\")\n",
    "ax.legend(loc=1)\n",
    "\n",
    "xfmt = dates.DateFormatter('%Y/%m')\n",
    "ax.xaxis.set_major_formatter(xfmt) \n",
    "plt.setp(ax.get_xticklabels(), rotation=40, ha=\"right\", rotation_mode=\"anchor\")\n",
    "\n",
    "foname = (output_imgdir+\"/tradeoff_logheal_dvvafterremovalfactors_focus_{}_{}_{}_{}.png\".format(stationpair, dvvmethod, freqband, modelparam[\"modelcase\"]))\n",
    "plt.savefig(foname, dpi=150, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data for master plot\n",
    "masterplot_data[\"xlimit_focus\"] = xlimit_focus\n",
    "masterplot_data[\"fitting_period_ind\"] = fitting_period_ind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply MCMC inversion with tmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Integration with low level callback function\n",
    "# read shared library\n",
    "lib_int = ctypes.CDLL(os.path.abspath('./LowLevel_callback_healing_distributed/healing_int.so'))\n",
    "lib_int.f.restype = ctypes.c_double\n",
    "lib_int.f.argtypes = (ctypes.c_int, ctypes.POINTER(ctypes.c_double), ctypes.c_void_p)\n",
    "    \n",
    "def logheal_llc(ts, S, taumin, taumax, lib_int):\n",
    "    # using Low-level caling function\n",
    "    # taumin = 0.1 # fix taumin so that healing starts just after incident\n",
    "    c = ctypes.c_double(ts) # time t as void * userdata\n",
    "    user_data = ctypes.cast(ctypes.pointer(c), ctypes.c_void_p)\n",
    "    int1_llc = LowLevelCallable(lib_int.f, user_data) # in this way, only void* is available as argument\n",
    "\n",
    "    return -S*integrate.quad(int1_llc, taumin, taumax, epsabs = 1e-3, epsrel=1e-3)[0] # this tolerance archieves our requirement in accuracy.\n",
    "\n",
    "def y_heal_llc(t, S, taumin, taumax, unix_tEV, lib_int):\n",
    "    if t < unix_tEV:\n",
    "        return 0\n",
    "    else:\n",
    "        # compute logheal model\n",
    "        return logheal_llc(t-unix_tEV, S, taumin, taumax, lib_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overwrite dvv_data and err data with fitting period\n",
    "modelparam_fit = copy.deepcopy(modelparam)\n",
    "modelparam_fit[\"xlimit_focus\"] = xlimit_focus\n",
    "modelparam_fit[\"fitting_period_ind\"] = fitting_period_ind\n",
    "modelparam_fit[\"unix_tvec\"] = modelparam[\"unix_tvec\"][fitting_period_ind]\n",
    "modelparam_fit[\"uniform_tvec\"] = uniform_tvec[fitting_period_ind]\n",
    "modelparam_fit[\"dvv_data\"] = dvv_data[fitting_period_ind]\n",
    "modelparam_fit[\"err_data\"] = err_data[fitting_period_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1096329600"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelparam_fit[\"unix_tPF\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply constraint\n",
    "S_range = [0, 0.6]\n",
    "tmin_range = [1e-3, 1.0] # years\n",
    "tmax_range = [0.7, 100] #[2, 100] # years\n",
    "\n",
    "#---Log probabilities---#\n",
    "def log_likelihood_PF(theta, **modelparam):\n",
    "    #parse parameters\n",
    "    S, tmin, tmax, log_f = theta\n",
    "    unix_tvec = modelparam[\"unix_tvec\"]\n",
    "    uniform_tvec = modelparam[\"uniform_tvec\"]\n",
    "    dvv_model= [y_heal_llc(t, S, 10**tmin, 10**tmax, modelparam[\"unix_tPF\"], lib_int) for t in unix_tvec]\n",
    "\n",
    "    dvv_data = modelparam[\"dvv_data\"]\n",
    "    err_data  = modelparam[\"err_data\"]\n",
    "    \n",
    "    # sigma2 = yerr_trim ** 2 + model ** 2 * np.exp(2 * log_f)\n",
    "    sigma2 = err_data ** 2 + np.exp(2 * log_f) # 2022.2.21 Applying constant over/under estimation in error\n",
    "\n",
    "#     #debug plot\n",
    "#     plt.plot(uniform_tvec, dvv_data, \"k-x\", label = \"data\")\n",
    "#     plt.plot(uniform_tvec, dvv_model, \"r-o\", label = \"model\")\n",
    "#     plt.legend(loc=1)\n",
    "#     plt.title(f\"residu: {np.linalg.norm(dvv_data - dvv_model):.8f}\")\n",
    "    \n",
    "    return -0.5 * np.nansum((dvv_data - dvv_model) ** 2 / sigma2 + np.log(sigma2)) # 2pi is ignored\n",
    "\n",
    "# assign boundary of parammeters as prior probability\n",
    "def log_prior_PF(theta, **modelparam):\n",
    "\n",
    "    S, logtmin, logtmax, log_f = theta\n",
    "\n",
    "    tmin = 10**logtmin\n",
    "    tmax = 10**logtmax\n",
    "    tmin_range_sec = np.array(tmin_range) *365*86400\n",
    "    tmax_range_sec = np.array(tmax_range) *365*86400\n",
    "\n",
    "    if (S<S_range[0]) or (S_range[1] < S): # We constrain 0<S<1.0 to avoid the large trade off between S, tmin and tmax\n",
    "        return -np.inf\n",
    "    \n",
    "    if (tmin<tmin_range_sec[0]) or (tmin_range_sec[1] < tmin):\n",
    "        return -np.inf\n",
    "    \n",
    "    if (tmax<tmax_range_sec[0]) or (tmax_range_sec[1] < tmax):\n",
    "        return -np.inf\n",
    "    \n",
    "    if (tmin>tmax):\n",
    "        return -np.inf\n",
    "    \n",
    "    if (-10.0 > log_f) or (log_f > -1.0):\n",
    "        return -np.inf\n",
    "    \n",
    "    # if all the trial parameters are within the boundaries, return 0.\n",
    "    return 0\n",
    "\n",
    "def log_probability_PF(theta0, **modelparam):\n",
    "    if len(theta0)==3:\n",
    "        theta=np.concatenate((theta0[0], modelparam[\"tmin_fixed\"], theta0[1:4]), axis=None)\n",
    "    elif len(theta0)==4:\n",
    "        theta = theta0 \n",
    "    else:\n",
    "        theta = theta0\n",
    "    \n",
    "    lp = log_prior_PF(theta, **modelparam)\n",
    "\n",
    "    if not np.isfinite(lp):\n",
    "        return -np.inf\n",
    "    \n",
    "    return lp + log_likelihood_PF(theta, **modelparam)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure the MCMC paramters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---parameters for MCMC---#\n",
    "modelparam_fit[\"nwalkers\"] = 16\n",
    "modelparam_fit[\"nsteps\"] = 10000\n",
    "mcmc_discard_nsample = 2000\n",
    "\n",
    "# We assign the initial value around the maximum likelihood paramters\n",
    "S_init = 0.06\n",
    "log10tmin_init= 7.0 # fix vmin with the value used for MCMC\n",
    "log10tmax_init= 8.0 # fix vmin with the value used for MCMC\n",
    "logf_init= -3.5 # fix vmin with the value used for MCMC\n",
    "\n",
    "caseid = 1 # case0: fix tmin case1: including tmin\n",
    "#-------------------------------------#\n",
    "\n",
    "if caseid == 0:\n",
    "    modelparam_fit[\"ndim\"] = 3\n",
    "    modelparam_fit[\"tmin_fixed\"] = log10tmin_init\n",
    "    modelparam_fit[\"pos\"] =  np.array([S_init, log10tmax_init, logf_init]) + 1e-4 * np.random.randn(modelparam_fit[\"nwalkers\"], modelparam_fit[\"ndim\"])\n",
    "        \n",
    "elif caseid == 1:\n",
    "    modelparam_fit[\"ndim\"] = 4\n",
    "    modelparam_fit[\"pos\"] =  np.array([S_init, log10tmin_init, log10tmax_init, logf_init]) + 1e-4 * np.random.randn(modelparam_fit[\"nwalkers\"], modelparam_fit[\"ndim\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.05997866,  6.99997122,  7.99993862, -3.49999254])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelparam_fit[\"pos\"][1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "538.4598921372539"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test log_probability\n",
    "log_probability_PF(modelparam_fit[\"pos\"][0, :], **modelparam_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [04:23<00:00, 37.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiprocessing took 264.0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(seed=20230501)\n",
    "\n",
    "sampler = emcee.EnsembleSampler(\n",
    "                modelparam_fit[\"nwalkers\"], modelparam_fit[\"ndim\"], log_probability_PF,\n",
    "                moves=[#emcee.moves.StretchMove(),\n",
    "                            (emcee.moves.DEMove(), 0.8),\n",
    "                            (emcee.moves.DESnookerMove(), 0.2),\n",
    "                            ],\n",
    "                kwargs=(modelparam_fit))\n",
    "\n",
    "start = time.time()\n",
    "sampler.run_mcmc(modelparam_fit[\"pos\"], modelparam_fit[\"nsteps\"], progress=True)\n",
    "end = time.time()\n",
    "multi_time = end - start\n",
    "print(\"Multiprocessing took {0:.1f} seconds\".format(multi_time))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check autocorrelation time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7257.18120935, 7484.05135303, 7888.78912556, 2261.96006246])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autocorr = emcee.autocorr.integrated_time(sampler.get_chain())\n",
    "autocorr * 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescale_chain(chain, caseid):\n",
    "    \"\"\"\n",
    "    rescale time\n",
    "    \"\"\"\n",
    "    if  len(chain.shape)==3:\n",
    "        # chains are not flatten\n",
    "        #log10time[s] -> log10time[year]\n",
    "        if caseid==0:\n",
    "            chain[:, :, 1] = np.log10(np.array([10**x/86400/365 for x in chain[:, :, 1]]))\n",
    "        else:\n",
    "            chain[:, :, 1] = np.log10(np.array([10**x/86400/365 for x in chain[:, :, 1]]))\n",
    "            chain[:, :, 2] = np.log10(np.array([10**x/86400/365 for x in chain[:, :, 2]]))\n",
    "        \n",
    "    elif len(chain.shape)==2:\n",
    "        # chains are flattern\n",
    "        if caseid==0:\n",
    "            chain[:, 1] = np.log10(np.array([10**x/86400/365 for x in chain[:, 1]]))\n",
    "        else:\n",
    "            chain[:, 1] = np.log10(np.array([10**x/86400/365 for x in chain[:, 1]]))\n",
    "            chain[:, 2] = np.log10(np.array([10**x/86400/365 for x in chain[:, 2]]))\n",
    "    else:\n",
    "        raise ValueError(\"size of chain is unknown.\") \n",
    "\n",
    "def rescale_theta(theta, caseid):\n",
    "    if caseid==0:\n",
    "        theta[1] = np.log10(10**theta[1]/86400/365)\n",
    "    elif caseid==1:\n",
    "        theta[1] = np.log10(10**theta[1]/86400/365)\n",
    "        theta[2] = np.log10(10**theta[2]/86400/365)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the chains of samples separately\n",
    "chains_samples = sampler.get_chain(discard=mcmc_discard_nsample, thin=1, flat=False)\n",
    "\n",
    "# get the chains of log probability\n",
    "chains_lnprob =  sampler.get_log_prob(discard=mcmc_discard_nsample, thin=1, flat=False)\n",
    "\n",
    "# select the chain id with the maximum log probability among the chains\n",
    "chains_lnprobmaxarg = np.argmax(chains_lnprob, axis=0)\n",
    "\n",
    "# extract the single chain of log probability with its maximum\n",
    "chains_lnprobmax = np.array([chains_lnprob[x, i] for i, x in enumerate(chains_lnprobmaxarg)])\n",
    "\n",
    "# compare the maximum log probability with different chains and get the best chain id\n",
    "lnprob_maxchain_id = np.argmax(chains_lnprobmax)\n",
    "\n",
    "# extract the best chain of samples\n",
    "flat_samples_maxprob = chains_samples[:, lnprob_maxchain_id, :]\n",
    "\n",
    "# obtain the model parameters with the best log probability\n",
    "maxlnprob_theta = copy.deepcopy(flat_samples_maxprob[chains_lnprobmaxarg[lnprob_maxchain_id], :])\n",
    "rescale_theta(maxlnprob_theta, caseid) # rescale t and blin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelparam[\"caseid\"] = caseid\n",
    "modelparam[\"maxlnprob_theta\"] = flat_samples_maxprob[chains_lnprobmaxarg[lnprob_maxchain_id], :]\n",
    "\n",
    "# Save the current state.\n",
    "foname = f\"{output_datadir}/tradeoff_Sandtmintmax_{stationpair}_{dvvmethod}_{freqband}_{modelparam_fit['modelcase']}_{caseid}_{modelparam_fit['nsteps']}.pickle\"\n",
    "\n",
    "with open(foname, \"wb\") as f:\n",
    "    pickle.dump(sampler, f)\n",
    "    pickle.dump(modelparam, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot using corner.corner\n",
    "# Reference: Foreman-Mackey (2016) https://corner.readthedocs.io/en/latest/\n",
    "chains_samples_all = copy.deepcopy(sampler.get_chain(discard=mcmc_discard_nsample, thin=1, flat=True))\n",
    "rescale_chain(chains_samples_all, caseid)\n",
    "\n",
    "if caseid==0:\n",
    "    labels = [\"$s_2$\", r\"$\\log_{10} \\tau_{2}^{max}$ [year]\", \"$\\log{f_0}$\"]\n",
    "    \n",
    "elif caseid==1:\n",
    "    labels = [\"$s_2$\", r\"$\\log_{10} \\tau_{2}^{min}$ [year]\", r\"$\\log_{10} \\tau_{2}^{max}$ [year]\", \"$\\log{f_0}$\"]\n",
    "    \n",
    "fig = corner.corner(\n",
    "    chains_samples_all, labels=labels, truths=maxlnprob_theta);\n",
    "\n",
    "fig.suptitle(f'channel weighted {stationpair} {dvvmethod}: {freqband}Hz')\n",
    "foname = (output_imgdir+f\"/MCMC_tradeoff_Sandtmintmax_cornerplot_{stationpair}_{dvvmethod}_{freqband}_{modelparam['modelcase']}_{caseid}_{modelparam['nsteps']}.png\")\n",
    "plt.savefig(foname, dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0665612949775076, 0.5998048378384822], [-0.6131598409582442, -0.0005938052369389086], [-0.14105075557506125, 0.3569630133294693], [-4.026805363657307, -3.5341970583932714]] [[-0.6131598409582442, -0.0005938052369389086], [-0.14105075557506125, 0.3569630133294693], [-4.026805363657307, -3.5341970583932714]]\n",
      "[[0.15, 0.3, 0.45], [-0.6, -0.45, -0.3, -0.15], [-0.1, 0.0, 0.1, 0.2, 0.3], [-4.0, -3.9, -3.8, -3.7, -3.6]] [[-0.6, -0.45, -0.3, -0.15], [-0.1, 0.0, 0.1, 0.2, 0.3], [-4.0, -3.9, -3.8, -3.7, -3.6]]\n"
     ]
    }
   ],
   "source": [
    "# Read ranges and ticks from corner plot\n",
    "if caseid == 0:\n",
    "    cornerticks_x_inds =np.arange(6, 9) # axes number of lower rows for x ticks\n",
    "    cornerticks_y_inds =np.arange(3, 9, 3)# axes number of lower rows for y ticks\n",
    "elif caseid == 1:\n",
    "    cornerticks_x_inds =np.arange(12, 16) # axes number of lower rows for x ticks\n",
    "    cornerticks_y_inds =np.arange(4, 16, 4)# axes number of lower rows for y ticks\n",
    "\n",
    "cornerranges_x = []\n",
    "cornerranges_y = []\n",
    "cornerticks_x = []\n",
    "cornerticks_y = []\n",
    "\n",
    "for i in cornerticks_x_inds:\n",
    "    cornerranges_x.append(list(fig.axes[i].get_xlim()))\n",
    "    cornerticks_x.append([np.round(x.get_unitless_position()[0], 10) for x in fig.axes[i].get_xticklabels()[:-1]])\n",
    "for j in cornerticks_y_inds:\n",
    "    cornerranges_y.append(list(fig.axes[j].get_ylim()))\n",
    "    cornerticks_y.append([np.round(y.get_unitless_position()[1], 10) for y in fig.axes[j].get_yticklabels()[:-1]])\n",
    "\n",
    "print(cornerranges_x, cornerranges_y)\n",
    "print(cornerticks_x, cornerticks_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "datainds_trim = range(len(labels[:-1]))  #[0, 1, 2] #range(len(labels[:-1])) # plot all quantities\n",
    "labels_trim=[labels[x] for x in datainds_trim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "modelparam[\"nbin_hist\"] = 16\n",
    "\n",
    "\n",
    "# flat_samples_maxprob\n",
    "\n",
    "fig0, axs, sm = plot_scattermatrix(chains_samples_all, datainds_trim, labels_trim, left=0.1, right=0.9, bottom=0.1, top=0.9, wspace=0.05, hspace=0.05,\n",
    "    xrange_sigma_factor=2, bincolorgray=0.7, nbin_hist=modelparam[\"nbin_hist\"], nbin_hist2d=18, Ncontourf=51, Ncontour=5, Ncontour_clip=4, cmap=\"Oranges\",\n",
    "    xticks=cornerticks_x, yticks=cornerticks_y, plot_truth=True,\n",
    "    ylim_max=0.3, zlim_max=0.04, xranges=cornerranges_x, plot_median=False, plot_bestparam=maxlnprob_theta, labelfontsize=11, tickfontsize=10, figsize=(5, 5));\n",
    "\n",
    "fig0.align_labels();\n",
    "\n",
    "fig0.suptitle(f'channel weighted {stationpair} {dvvmethod}: {freqband}Hz')\n",
    "# plt.subplots_adjust(top=0.9)\n",
    "\n",
    "foname = (output_imgdir+f\"/MCMC_tradeoff_Sandtmintmax_scattermatrix_{stationpair}_{dvvmethod}_{freqband}_{modelparam['modelcase']}_{caseid}_{modelparam['nsteps']}.png\")\n",
    "plt.savefig(foname, dpi=150, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc = mpl.cm.Set2_r(np.linspace(0,1,sampler.nwalkers))\n",
    "xmax = modelparam_fit[\"nsteps\"]+500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_log_prob_plot = sampler.get_log_prob(discard=0, thin=1, flat=False) # retrieve all the log prob history\n",
    "max_logprob_ind = chains_lnprobmaxarg[lnprob_maxchain_id] # plot the iteration of max log prob\n",
    "\n",
    "samples = copy.deepcopy(sampler.get_chain(discard=0, thin=1, flat=False)) # retrieve all the samples with separate chain\n",
    "rescale_chain(samples, caseid)\n",
    "\n",
    "fig, axes = plt.subplots(sampler.ndim+1, figsize=(10, 12), sharex=True)\n",
    "lw_maxprob = 0.6\n",
    "\n",
    "labelfontsize = 10.8\n",
    "\n",
    "# append the limit of log prob\n",
    "ylim_list = copy.deepcopy(cornerranges_x)\n",
    "maxprobval = chain_log_prob_plot[max_logprob_ind+mcmc_discard_nsample, lnprob_maxchain_id]\n",
    "ylim_list.append([0.98*maxprobval, 1.005*maxprobval])\n",
    "\n",
    "for i in range(sampler.ndim):\n",
    "    ax = axes[i]\n",
    "    \n",
    "    for j in range(sampler.nwalkers):\n",
    "        ax.plot(samples[:, j, i], lw=0.5, c=lc[j, :], alpha=0.8)\n",
    "        \n",
    "    # plot the chain with maximum log probability\n",
    "    ax.plot(samples[:, lnprob_maxchain_id, i], c=\"k\", lw=lw_maxprob) \n",
    "    \n",
    "    ax.set_xlim([0, xmax])\n",
    "    ax.set_ylim(ylim_list[i])\n",
    "    ax.set_ylabel(labels[i], fontsize=labelfontsize)\n",
    "#     ax.yaxis.set_label_coords(-0.1, 0.5)\n",
    "    ax.axvline(mcmc_discard_nsample, c=\"k\", ls=\"--\")\n",
    "    # plot maximum likelihood parameters\n",
    "    ax.axhline(maxlnprob_theta[i], c=\"b\", ls=\":\", lw=1.0)\n",
    "    ax.plot(max_logprob_ind+mcmc_discard_nsample, maxlnprob_theta[i], \"ro\", ms=6, markeredgecolor=\"w\");\n",
    "\n",
    "# plot maximum log probability\n",
    "plot_logprob = chain_log_prob_plot[:, lnprob_maxchain_id]\n",
    "\n",
    "ax = axes[-1]\n",
    "for i in range(chain_log_prob_plot.shape[1]):\n",
    "    ax.plot(chain_log_prob_plot[:, i], lw=0.5, c=lc[i, :], alpha=0.8);\n",
    "\n",
    "ax.axvline(mcmc_discard_nsample, c=\"k\", ls=\"--\")\n",
    "# plot the chain with maximum log probability\n",
    "ax.plot(plot_logprob, c=\"k\", lw=lw_maxprob)\n",
    "ax.axhline(chain_log_prob_plot[max_logprob_ind+mcmc_discard_nsample, lnprob_maxchain_id], c=\"b\", ls=\":\", lw=1.0)\n",
    "ax.plot(max_logprob_ind+mcmc_discard_nsample, maxprobval, \"ro\", ms=6, markeredgecolor=\"w\");\n",
    "\n",
    "ax.set_xlim([0, xmax])\n",
    "ax.set_ylim(ylim_list[-1])\n",
    "ax.set_ylabel(\"$\\log{L}$\", fontsize=labelfontsize)\n",
    "\n",
    "axes[-1].set_xlabel(\"step number\");\n",
    "plt.subplots_adjust(bottom=0.1, right=0.8, top=0.9)\n",
    "\n",
    "foname = (output_imgdir+f\"/MCMC_tradeoff_Sandtmintmax_allchains_{stationpair}_{dvvmethod}_{freqband}_{modelparam['modelcase']}_{caseid}_{modelparam['nsteps']}.png\")\n",
    "\n",
    "fig.suptitle(f'channel weighted {stationpair} {dvvmethod}: {freqband}Hz')\n",
    "fig.tight_layout(rect=[0,0,1,1])\n",
    "plt.subplots_adjust(hspace=0.2)\n",
    "fig.align_ylabels()\n",
    "\n",
    "plt.savefig(foname, dpi=150, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save data for master plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "masterplot_data[\"mcmc_discard_nsample\"] = mcmc_discard_nsample\n",
    "masterplot_data[\"labels\"] = labels\n",
    "masterplot_data[\"S_range\"] = S_range\n",
    "masterplot_data[\"tmin_range\"] = tmin_range\n",
    "masterplot_data[\"tmax_range\"] = tmax_range\n",
    "masterplot_data[\"cornerranges_x\"] = cornerranges_x\n",
    "masterplot_data[\"cornerranges_y\"] = cornerranges_y\n",
    "masterplot_data[\"cornerticks_x\"] = cornerticks_x\n",
    "masterplot_data[\"cornerticks_y\"] = cornerticks_y\n",
    "\n",
    "# Save the current state.\n",
    "foname = f\"{output_datadir}/tradeoff_Sandtmintmax_masterdata_{stationpair}_{dvvmethod}_{freqband}_{modelparam_fit['modelcase']}_{caseid}_{modelparam_fit['nsteps']}.pickle\"\n",
    "\n",
    "with open(foname, \"wb\") as f:\n",
    "    pickle.dump(sampler, f)\n",
    "    pickle.dump(masterplot_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['stationpair', 'dvvmethod', 'freqband', 'modelcase', 'uniform_tvec', 'unix_tvec', 'unix_SS', 'unix_tPF', 'dvv_data', 'dvv_data_PF', 'xlimit_focus', 'fitting_period_ind', 'mcmc_discard_nsample', 'labels', 'S_range', 'tmin_range', 'tmax_range', 'cornerranges_x', 'cornerranges_y', 'cornerticks_x', 'cornerticks_y'])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masterplot_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
