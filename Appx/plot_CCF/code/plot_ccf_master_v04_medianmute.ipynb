{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot CCF over 20 years\n",
    "\n",
    "2023.3.25 Kurama Okubo\n",
    "\n",
    "This notebook plots the result of CCF.\n",
    "\n",
    "- 2023.4.17 update to plot 3 components tiles\n",
    "- 2023.4.27 update to implement median mute for reference stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "import time\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "%matplotlib inline\n",
    "from IPython.display import display, Math\n",
    "import seaborn as sns \n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import pickle\n",
    "\n",
    "import matplotlib as mpl\n",
    "\n",
    "plt.rcParams[\"font.family\"] = 'Arial'\n",
    "# plt.rcParams[\"font.sans-serif\"] = \"DejaVu Sans, Arial, Helvetica, Lucida Grande, Verdana, Geneva, Lucid, Avant Garde, sans-serif\"\n",
    "plt.rcParams[\"font.size\"] = 12\n",
    "plt.rcParams[\"xtick.direction\"] = \"in\"\n",
    "plt.rcParams[\"xtick.major.size\"] = 5\n",
    "plt.rcParams[\"xtick.major.width\"] = 0.5\n",
    "plt.rcParams[\"xtick.minor.size\"] = 2\n",
    "plt.rcParams[\"xtick.minor.width\"] = 1\n",
    "plt.rcParams[\"xtick.minor.visible\"] = True\n",
    "\n",
    "\n",
    "plt.rcParams[\"ytick.direction\"] = \"in\"\n",
    "plt.rcParams[\"ytick.major.size\"] = 5\n",
    "plt.rcParams[\"ytick.major.width\"] = 0.5\n",
    "plt.rcParams[\"ytick.minor.size\"] = 2\n",
    "plt.rcParams[\"ytick.minor.width\"] = 1\n",
    "plt.rcParams[\"ytick.minor.visible\"] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---Parameters---#\n",
    "fidir = \"../data_npz\"\n",
    "freqkey = \"0.9-1.2\"\n",
    "output_imgdir = \"../figure/ccf_master\"\n",
    "cc_medianmute_max = 3.0\n",
    "cc_medianmute_min = 0.1\n",
    "\n",
    "starttime = datetime.datetime(2002, 1, 1)\n",
    "endtime = datetime.datetime(2022, 6, 1)\n",
    "\n",
    "refstack_starttime = datetime.datetime(2010, 1, 1)\n",
    "refstack_endtime = datetime.datetime(2022, 6, 1)\n",
    "\n",
    "if not os.path.exists(output_imgdir):\n",
    "    os.makedirs(output_imgdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpalette=np.array(sns.color_palette(\"colorblind\"))[:]\n",
    "lc_lin = cpalette[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.color_palette(\"colorblind\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read BP stations\n",
    "loc_table = \"./BP_gmap-stations.txt\"\n",
    "df_raw = pd.read_csv(loc_table, skiprows=3, header=None, sep = '|')\n",
    "stationlist = np.sort(df_raw[1].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stationlist\n",
    "Nstation = len(stationlist)\n",
    "# make station pairs\n",
    "\n",
    "stationpair_list = []\n",
    "\n",
    "for i in range(Nstation):\n",
    "    jinit = i\n",
    "    for j in range(jinit, Nstation):\n",
    "        sta1 = stationlist[i]\n",
    "        sta2 = stationlist[j]\n",
    "        stationpair_list.append(f\"BP.{sta1}-BP.{sta2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['11', '12', '13', '21', '22', '23', '31', '32', '33']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complist = [\"11\",\"12\",\"13\",\"21\",\"22\",\"23\",\"31\",\"32\",\"33\"]\n",
    "complist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #---develop median mute---#\n",
    "# cc_medianmute_max = 3.0\n",
    "# cc_medianmute_min = 0.1\n",
    "\n",
    "# stationpair = 'BP.EADB-BP.EADB'\n",
    "# comp = '22'\n",
    "# fi_stachanpair = f\"{stationpair}-{comp}\"\n",
    "# D = np.load(fidir+f\"/corrdata_{fi_stachanpair}_{freqkey}.npz\")\n",
    "# lags = D[\"lags\"]\n",
    "# t = D[\"t\"]\n",
    "# corr_raw = D[\"corr\"]\n",
    "\n",
    "# cc_maxamp = np.max(np.abs(corr_raw), axis=0)\n",
    "# cc_medianamp = np.nanmedian(cc_maxamp)\n",
    "# cc_medianamp\n",
    "# inds = np.where((cc_maxamp <= cc_medianmute_max*cc_medianamp) & (cc_medianmute_min*cc_medianamp <= cc_maxamp))[0]\n",
    "# stack =  np.mean(corr_raw[:, inds], axis=1)\n",
    "# plt.plot(stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_plotcorrdata(stationpair, comp):\n",
    "\n",
    "    fi_stachanpair = f\"{stationpair}-{comp}\"\n",
    "    D = np.load(fidir+f\"/corrdata_{fi_stachanpair}_{freqkey}.npz\")\n",
    "    lags = D[\"lags\"]\n",
    "    t = D[\"t\"]\n",
    "    corr_raw = D[\"corr\"]\n",
    "    linstack_raw = D[\"linstack\"]\n",
    "    codainit = D[\"codainit\"]\n",
    "    codaend = D[\"codaend\"]\n",
    "\n",
    "    # compute abs_max the corr data and linear stacked data\n",
    "    max_corr_raw = np.max(np.abs(corr_raw), axis=0)\n",
    "    # avoid zero division when the corr data is all zero.\n",
    "    # This happens when the sparse data sets are correlated, but it is only a few cases.\n",
    "    max_corr_raw[max_corr_raw==0] = np.nan # replace that row as nan \n",
    "    corr = corr_raw / max_corr_raw\n",
    "    linstack = linstack_raw / np.max(np.abs(linstack_raw), axis=0)\n",
    "\n",
    "    # convert tvec to datetime\n",
    "    # NOTE: The time is not always start from 0H00M, which occurs due to the lack of hourly CCF when computing daily-stacked CCF.\n",
    "    uniform_tvec = np.array([datetime.datetime.utcfromtimestamp(x) for x in t])\n",
    "\n",
    "    # compute refstack:\n",
    "    # NOTE: linstack is done from 2002-1-1 to 2022-6-1 during the conversion with Julia script.\n",
    "    # We add one more reference stack corresponding to the one used in the actual postprocess.\n",
    "    ref_tind = np.where((refstack_starttime <= uniform_tvec) & (uniform_tvec <= refstack_endtime))[0]\n",
    "    # compute the reference stack\n",
    "    # Update: implement the mediean mute\n",
    "    corr_ref = corr_raw[:, ref_tind]\n",
    "    \n",
    "    cc_maxamp = np.max(np.abs(corr_ref), axis=0)\n",
    "    cc_medianamp = np.nanmedian(cc_maxamp)\n",
    "    median_inds = np.where((cc_maxamp <= cc_medianmute_max*cc_medianamp) & (cc_medianmute_min*cc_medianamp <= cc_maxamp))[0]\n",
    "    refstack_raw =  np.mean(corr_ref[:, median_inds], axis=1)\n",
    "#     refstack_raw = np.mean(corr_raw[:, ref_tind], axis=1)\n",
    "    refstack = refstack_raw / np.max(np.abs(refstack_raw), axis=0)\n",
    "\n",
    "    return (lags, uniform_tvec, codainit, codaend, corr, linstack, refstack)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download .npz data from dasway\n",
    "To demonstrate the plotting of CCFs, we download the data from dasway.\n",
    "You can generate the `.npz` file by downloading the channel-collected `.jld2` files and using `convert_ccf_threads_uwcascadia.jl`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference: https://stackoverflow.com/a/62113293\n",
    "def download(url: str, fname: str):\n",
    "    resp = requests.get(url, stream=True)\n",
    "    total = int(resp.headers.get('content-length', 0))\n",
    "    # Can also replace 'file' with a io.BytesIO object\n",
    "    with open(fname, 'wb') as file, tqdm(\n",
    "        desc=fname,\n",
    "        total=total,\n",
    "        unit='iB',\n",
    "        unit_scale=True,\n",
    "        unit_divisor=1024,\n",
    "    ) as bar:\n",
    "        for data in resp.iter_content(chunk_size=1024):\n",
    "            size = file.write(data)\n",
    "            bar.update(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the station pair to plot\n",
    "stationpair = \"BP.LCCB-BP.SCYB\" #stationpair_list[0]\n",
    "sta1, sta2 = stationpair.split(\"-\")\n",
    "sta1 = sta1.split(\".\")[-1]\n",
    "sta2 = sta2.split(\".\")[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading the data of BP.LCCB-BP.SCYB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../data_npz/corrdata_BP.LCCB-BP.SCYB-11_0.9-1.2.npz: 100%|█| 53.2M/53.2M [01:37<\n",
      "../data_npz/corrdata_BP.LCCB-BP.SCYB-12_0.9-1.2.npz: 100%|█| 53.6M/53.6M [02:04<\n",
      "../data_npz/corrdata_BP.LCCB-BP.SCYB-13_0.9-1.2.npz: 100%|█| 50.1M/50.1M [01:22<\n",
      "../data_npz/corrdata_BP.LCCB-BP.SCYB-21_0.9-1.2.npz: 100%|█| 53.2M/53.2M [02:17<\n",
      "../data_npz/corrdata_BP.LCCB-BP.SCYB-22_0.9-1.2.npz: 100%|█| 53.6M/53.6M [02:13<\n",
      "../data_npz/corrdata_BP.LCCB-BP.SCYB-23_0.9-1.2.npz: 100%|█| 50.1M/50.1M [01:51<\n",
      "../data_npz/corrdata_BP.LCCB-BP.SCYB-31_0.9-1.2.npz: 100%|█| 53.2M/53.2M [02:05<\n",
      "../data_npz/corrdata_BP.LCCB-BP.SCYB-32_0.9-1.2.npz: 100%|█| 53.6M/53.6M [02:04<\n",
      "../data_npz/corrdata_BP.LCCB-BP.SCYB-33_0.9-1.2.npz: 100%|█| 50.1M/50.1M [01:45<\n"
     ]
    }
   ],
   "source": [
    "print(f\"Downloading the data of {stationpair}\")\n",
    "\n",
    "for comp in complist:\n",
    "    url=f'https://dasway.ess.washington.edu/shared/kokubo/parkfield_ccf_data_npz/corrdata_{stationpair}-{comp}_0.9-1.2.npz' # download the data from dasway\n",
    "    foname=os.path.join(fidir, f'corrdata_{stationpair}-{comp}_0.9-1.2.npz')\n",
    "    download(url, foname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot parameter\n",
    "vmin = -1.0\n",
    "vmax = 1.0\n",
    "tmax = 50\n",
    "gcm = \"seismic\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(6, 3, figsize=(12, 14.3), sharex=False, gridspec_kw={'height_ratios': [4, 1, 4, 1, 4, 1]})\n",
    "fig.suptitle(f\"{sta1}-{sta2} {freqkey}Hz\");\n",
    "\n",
    "# Loop with 3 channel correlations    \n",
    "for comp in complist:\n",
    "\n",
    "    comp1, comp2 = comp\n",
    "    comp1 = int(comp1)\n",
    "    comp2 = int(comp2)\n",
    "\n",
    "    fi_stachanpair =  f\"{stationpair}-{comp}\"\n",
    "    if not os.path.isfile(fidir+f\"/corrdata_{fi_stachanpair}_{freqkey}.npz\"):\n",
    "        print(f\"{fi_stachanpair} file not exists. skipping.\")\n",
    "        continue\n",
    "\n",
    "    lags, uniform_tvec, codainit, codaend, corr, linstack, refstack = get_plotcorrdata(stationpair, f\"{comp1}{comp2}\")\n",
    "\n",
    "    p1, p2 = [2*(comp1-1), comp2-1]\n",
    "    \n",
    "    # plot contour\n",
    "    axs[p1, p2].pcolormesh(lags, uniform_tvec, np.transpose(corr), cmap=gcm, vmin=vmin, vmax=vmax, rasterized=True, )\n",
    "\n",
    "    axs[p1, p2].set_xlim([-tmax, tmax])\n",
    "    axs[p1, p2].set_xticks(np.linspace(-tmax, tmax, 11))\n",
    "    axs[p1, p2].set_ylim([starttime, endtime])\n",
    "\n",
    "    if f\"{comp1}{comp2}\" == \"11\":\n",
    "        subplottitle = \"11 (ZZ)\"\n",
    "    else:\n",
    "        subplottitle = f\"{comp1}{comp2}\"\n",
    "\n",
    "    axs[p1, p2].set_title(subplottitle)\n",
    "    loc = mdates.YearLocator(2)\n",
    "    axs[p1, p2].yaxis.set_major_locator(loc)\n",
    "    fmt = mdates.DateFormatter('%Y')\n",
    "    axs[p1, p2].yaxis.set_major_formatter(fmt)\n",
    "    axs[p1, p2].set_xlabel(\"Time lag [s]\")\n",
    "\n",
    "    # coda window\n",
    "    for i in range(2):\n",
    "        axs[p1, p2].axvline(codainit[i], ls=\"--\", c='k', lw=1.0)\n",
    "        axs[p1, p2].axvline(codaend[i], ls=\"--\", c='k', lw=1.0)\n",
    "\n",
    "    # reference window\n",
    "    axs[p1, p2].axhline(refstack_starttime, ls=\":\", c='k', lw=1.5)\n",
    "    axs[p1, p2].axhline(refstack_endtime, ls=\":\", c='k', lw=1.5)\n",
    "\n",
    "    axs[p1+1, p2].plot(lags, refstack, \"k-\", lw=0.6)\n",
    "    axs[p1+1, p2].plot(lags, linstack, \":\", c=lc_lin, lw=0.6)\n",
    "    axs[p1+1, p2].set_xlim([-tmax, tmax])\n",
    "    axs[p1+1, p2].set_ylim([-1.2, 1.2])\n",
    "    axs[p1+1, p2].set_xticks(np.linspace(-tmax, tmax, 11))\n",
    "    axs[p1+1, p2].set_xlabel(\"Time lag [s]\")\n",
    "    axs[p1+1, p2].set_ylabel(\"Normalized\\namplitude\")\n",
    "\n",
    "    for i in range(2):\n",
    "        axs[p1+1, p2].axvline(codainit[i], ls=\"--\", c='k', lw=1.0)\n",
    "        axs[p1+1, p2].axvline(codaend[i], ls=\"--\", c='k', lw=1.0)\n",
    "        \n",
    "    \n",
    "fig.tight_layout(rect=[0,0,1,1.0])\n",
    "plt.subplots_adjust(hspace=0.45, wspace=0.3)\n",
    "\n",
    "for i in [0, 2, 4]:\n",
    "    for j in range(3):\n",
    "        pos1 = axs[i, j].get_position() # get the original position \n",
    "        pos2 = [pos1.x0, 0.983*pos1.y0,  pos1.width, pos1.height] \n",
    "        axs[i, j].set_position(pos2) # set a new position\n",
    "\n",
    "fig.subplots_adjust(bottom=0.09)\n",
    "cbar_ax = fig.add_axes([0.0615, 0.04, 0.9, 0.07])\n",
    "cbar_ax.set_axis_off()\n",
    "# (left, bottom, width, height)\n",
    "normalize = mpl.colors.Normalize(vmin=vmin, vmax=vmax)\n",
    "cbar=fig.colorbar(mpl.cm.ScalarMappable(norm=normalize, cmap=gcm),\n",
    "                 orientation='horizontal', ax=cbar_ax, location = 'bottom',\n",
    "                 label=\"Normalized amplitude\")\n",
    "\n",
    "# add text box for the annotation of stacked lines\n",
    "legend_ax = fig.add_axes([0.7, 0.025, 0.3, 0.02])\n",
    "legend_ax.plot([], [], \"k-\", label=f'reference stack {refstack_starttime.strftime(\"%Y/%m\")}-{refstack_endtime.strftime(\"%Y/%m\")}') # dummy data for legend\n",
    "legend_ax.plot([], [], \":\", c=lc_lin, label=f'all stack {starttime.strftime(\"%Y/%m\")}-{endtime.strftime(\"%Y/%m\")}')\n",
    "legend_ax.legend(loc=10)\n",
    "legend_ax.set_axis_off()\n",
    "\n",
    "foname = (output_imgdir+\"/ccf_master_allcomp_{}_{}Hz.png\".format(stationpair, freqkey))\n",
    "plt.savefig(foname, dpi=150)\n",
    "# plt.clf()\n",
    "# plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
